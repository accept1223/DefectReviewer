# DefectReviewer

This repository contains the implementation and experimental code of the paper:

**DefectReviewer: Towards Generating Defect-Focused Review Comment Based on Fine-Grained Defect Localization**

![Approach Overview](Overview.jpg)


ğŸ“ Project Structure
```
.
â”œâ”€â”€ configs/ # Configuration files for training and inference
â”œâ”€â”€ data/ # Preprocessed datasets and data-related utilities
â”œâ”€â”€ environment.yml # Conda environment specification
â”œâ”€â”€ inference.py # Inference script for review comment generation
â”œâ”€â”€ metrics/ # Evaluation metrics (e.g., BLEU, ROUGE-L)
â”œâ”€â”€ models/ # Model definitions and wrappers
â”œâ”€â”€ trainers/ # Training logic and trainer utilities
â”œâ”€â”€ utils/ # Helper functions (logging, I/O, preprocessing)
â”œâ”€â”€ train.py # Training entry point
â””â”€â”€ Overview.jpg # Overview of the proposed approach
```

âš™ï¸ Setup
1. Clone the repository

2. Create Conda environment

```conda env create -f environment.yml```

ğŸ“¦ Dataset

```unzip data/dataset.zip -d data/```

ğŸ§  Models

DefectReviewer supports multiple pre-trained language models for code review comment generation. Pre-trained models (e.g., CodeLLaMA or DeepSeek-Coder) can be obtained from public model repositories such as HuggingFace by specifying the corresponding model identifiers in the configuration files. Fine-tuned model checkpoints should be placed in the appropriate directories as specified in the configs.

ğŸš€ Training

To train DefectReviewer, run:

```accelerate launch train.py```

Training behavior (model choice, localization signals, hyperparameters) can be configured via files in the configs/ directory.

ğŸ“Š Evaluation Metrics

Metrics are computed automatically after inference.

ğŸ™‹ Contact

Feel free to open an issue or contact us if you have any questions or feedback.

